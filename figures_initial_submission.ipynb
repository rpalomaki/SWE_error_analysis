{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import re\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import sys\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patheffects as pe\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import patches\n",
    "import matplotlib.ticker as mtick\n",
    "sys.path.append('src')\n",
    "from src.swe_retrievals import *\n",
    "from src.plotting_functions import *\n",
    "\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "warnings.simplefilter('ignore', RuntimeWarning)\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "warnings.simplefilter('ignore', SettingWithCopyWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1 - workflow example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_type = 'soil'\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "paradise = plot_swe_curves(station_id=679, wateryear=2021, ax1=ax[0], ax2=ax[1], extra_title_text='\\n(Deep snowpack)', return_data=True, plot_legends=False)\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Create a 2x3 grid\n",
    "gs = gridspec.GridSpec(2, 3, figure=fig)\n",
    "# Left column split into two rows\n",
    "ax0 = fig.add_subplot(gs[0, 0])  # top-left\n",
    "ax1 = fig.add_subplot(gs[1, 0])  # bottom-left\n",
    "\n",
    "# Middle and right panels span both rows\n",
    "ax2 = fig.add_subplot(gs[:, 1])  # middle\n",
    "ax3 = fig.add_subplot(gs[:, 2])  # right\n",
    "\n",
    "paradise[0]['soil_moisture_pct'].plot(ax=ax0, color='k')\n",
    "paradise[0][f'{error_type}_error'].plot(ax=ax1, color='k')\n",
    "\n",
    "for data in paradise[1].values():\n",
    "    data.loc['2020-10-01':'2021-07-01',f'{error_type}_error_cumsum'].plot(ax=ax2, marker='o')\n",
    "    \n",
    "test = pd.concat([paradise[1][f'12d_{i}'][f'{error_type}_error_cumsum'] for i in range(12)]).sort_index()\n",
    "test.loc['2020-10-01':'2021-07-01'].plot(ax=ax3, label='Daily data')\n",
    "test.loc['2020-10-01':'2021-07-01'].rolling('12d').mean().plot(ax=ax3, label='Rolling 12d mean', lw=3)\n",
    "leg = ax3.legend(fontsize=11, bbox_to_anchor=[0.98, 0.3], loc='upper right')\n",
    "for legobj in leg.legend_handles:\n",
    "    legobj.set_linewidth(2.0)\n",
    "\n",
    "# paradise[0]['soil_error'].cumsum().plot(ax=ax[2], color='r')\n",
    "\n",
    "ax1.hlines(0, *ax1.get_xlim(), 'k', ls='--', lw=2)\n",
    "ax2.hlines(0, *ax1.get_xlim(), 'k', ls='--', lw=2)\n",
    "ax3.hlines(0, *ax1.get_xlim(), 'k', ls='--', lw=2)\n",
    "\n",
    "ax0.set_ylabel('Soil moisture [%]', fontsize=12, labelpad=24)\n",
    "ax1.set_ylabel('12-day SWE error [m]', fontsize=12)\n",
    "ax2.set_ylabel('Cumulative SWE error [m]', fontsize=14)\n",
    "ax3.set_ylabel('Cumulative SWE error [m]', fontsize=14)\n",
    "\n",
    "good_xticks = ax3.get_xticks()\n",
    "good_xticklabels = ax3.get_xticklabels()\n",
    "\n",
    "ax0.tick_params(labelbottom=False)\n",
    "ax2.tick_params(axis='x', which='minor', bottom=False, labelsize=12)\n",
    "ax3.tick_params(axis='x', which='minor', bottom=False, labelsize=12)\n",
    "ax2.tick_params(axis='both', labelsize=12)\n",
    "ax3.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "for axx in [ax0, ax1]:\n",
    "    axx.tick_params(axis='x', which='minor', bottom=False)\n",
    "    axx.set_xlabel('')\n",
    "    axx.set_xlim(ax2.get_xlim())\n",
    "    axx.set_xticks(good_xticks)\n",
    "    axx.set_xticklabels(good_xticklabels, fontsize=12, rotation=0, ha='center')\n",
    "    axx.set_yticklabels(axx.get_yticklabels(), fontsize=12)\n",
    "    \n",
    "ax0.text(0.02, 0.88, 'a)', transform=ax0.transAxes, fontsize=14)\n",
    "ax1.text(0.02, 0.05, 'b)', transform=ax1.transAxes, fontsize=14)\n",
    "ax2.text(0.02, 0.94, 'c)', transform=ax2.transAxes, fontsize=14)\n",
    "ax3.text(0.02, 0.93, 'd)', transform=ax3.transAxes, fontsize=14)\n",
    "\n",
    "\n",
    "ax0.set_title('Paradise station\\nPeak SWE = 2.37 m on 2021-04-19', linespacing=1.5)\n",
    "ax2.set_title('Cumulative SWE error from soil permittivity changes\\nAll possible 12-day baselines', linespacing=1.5)\n",
    "ax3.set_title('Cumulative errors from all 12-day baselines\\ncondensed into one continuous daily timeseries', linespacing=1.5)\n",
    "# ax[2].set_title('Cumulative sum of daily soil error\\n(not split into 12-day cycles)')\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig('local/figs/initial_submission/figure1.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2 - single season timeseries plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = pd.read_csv('/pl/active/palomaki-sar/insar_swe_errors/data/snotel/fig4_sites.csv').dropna(subset='ecoregion')\n",
    "# site = sites.loc[sites['station_id']==station_id]\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(11.5*0.8,14*0.8))#, gridspec_kw={'wspace':0.4,'hspace':0.3})\n",
    "paradise = plot_swe_curves(station_id=679, wateryear=2021, ax1=ax[0,0], ax2=ax[0,1], extra_title_text='\\n(Deep snowpack)', return_data=True, plot_legends=False)\n",
    "trial = plot_swe_curves(station_id=828, wateryear=2017, ax1=ax[1,0], ax2=ax[1,1], extra_title_text='\\n(Moderate snowpack)', return_data=True) #828 2017\n",
    "disaster = plot_swe_curves(station_id=445, wateryear=2019, ax1=ax[2,0], ax2=ax[2,1], extra_title_text='\\n(Shallow snowpack)', return_data=True, plot_legends=False)\n",
    "ymin = min([ax.get_ylim()[0] for ax in ax[0]])\n",
    "ymax = max([ax.get_ylim()[1] for ax in ax[0]])\n",
    "for axx in ax[:,0]:\n",
    "    axx.set_ylim([-0.6, 3.1])\n",
    "for axx in ax[:,1]:\n",
    "    axx.set_ylim([-0.16, 0.16])\n",
    "    \n",
    "ax[0,0].hlines(0, *ax[0,0].get_xlim(), lw=1.5, color='k', ls='--', zorder=0)\n",
    "ax[1,0].hlines(0, *ax[1,0].get_xlim(), lw=1.5, color='k', ls='--', zorder=0)\n",
    "ax[2,0].hlines(0, *ax[2,0].get_xlim(), lw=1.5, color='k', ls='--', zorder=0)\n",
    "\n",
    "    \n",
    "plt.tight_layout()\n",
    "# fig.savefig('local/figs/initial_submission/figure2.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis for Figures 3 and 4 - calculate cumulative rolling errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = gpd.read_file('local/median_errors_accum_only_nonabs.csv')\n",
    "# sites = gpd.read_file('local/median_errors_accum_only_nonabs_simplemedian.csv')\n",
    "sites['ecoregion'].replace('', np.nan, inplace=True)\n",
    "sites.dropna(subset='ecoregion', inplace=True)\n",
    "for c in sites.columns:\n",
    "    try:\n",
    "        sites[c] = pd.to_numeric(sites[c])\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "sites = sites[['ecoregion', 'station_name', 'station_id', 'lat', 'lon', 'elev', 'sand',\n",
    "               'clay', 'sturm', 'landfire', 'canopy_height', 'state', 'timezone']]\n",
    "sites[['defo_error_cumsum_rolling','soil_error_cumsum_rolling','veg_error_cumsum_rolling',\n",
    "       'dry_atmo_error_cumsum_rolling','wet_atmo_error_cumsum_rolling','ion_error_cumsum_rolling']] = np.nan\n",
    "\n",
    "dowy = 183 # 152=March 1, 183=April1\n",
    "\n",
    "for i, site in sites.iterrows():\n",
    "    try:\n",
    "        gb_tmp = calculate_avg_cumsum_errors(site['station_id'])\n",
    "        avg_errors = gb_tmp.mean().loc[dowy,['defo_error_cumsum_rolling','soil_error_cumsum_rolling','veg_error_cumsum_rolling',\n",
    "                         'dry_atmo_error_cumsum_rolling','wet_atmo_error_cumsum_rolling','ion_error_cumsum_rolling','swe_m']]# / gb_tmp.mean().loc[183, 'swe_m']\n",
    "        avg_errors.rename(index={'swe_m':'accumulated_swe_m'})\n",
    "    #     avg_errors['total_error'] = avg_errors.sum()\n",
    "        sites.loc[i, avg_errors.index] = avg_errors\n",
    "    except:\n",
    "        print('bad site')\n",
    "        continue\n",
    "\n",
    "sites.to_csv('data/median_cumulative_errors_april1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = gpd.read_file('local/median_errors_accum_only_nonabs.csv')\n",
    "sites['ecoregion'].replace('', np.nan, inplace=True)\n",
    "sites.dropna(subset='ecoregion', inplace=True)\n",
    "sites['map_number'] = [1,3,7,8,4,9,10,2,5,6,11,12,13]\n",
    "for c in sites.columns:\n",
    "    try:\n",
    "        sites[c] = pd.to_numeric(sites[c])\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "sites = sites[['ecoregion', 'station_name', 'station_id', 'lat', 'lon', 'elev', 'sand',\n",
    "               'clay', 'sturm', 'landfire', 'canopy_height', 'state', 'timezone','map_number']]\n",
    "sites[['defo_error_cumsum_rolling','soil_error_cumsum_rolling','veg_error_cumsum_rolling',\n",
    "       'dry_atmo_error_cumsum_rolling','wet_atmo_error_cumsum_rolling','ion_error_cumsum_rolling','total_error']] = np.nan\n",
    "\n",
    "dowy = 183 # 152=March 1, 183=April1\n",
    "error_df = pd.DataFrame(index=sites['station_name'], columns=np.arange(2016,2026), dtype=float)\n",
    "swe_df = pd.DataFrame(index=sites['station_name'], columns=np.arange(2016,2026), dtype=float)\n",
    "\n",
    "for i, site in sites.iterrows():\n",
    "    gb_tmp = calculate_avg_cumsum_errors(site['station_id'])\n",
    "    error_tmp = gb_tmp.get_group(dowy)['cumsum_no_ion'] \n",
    "    swe_tmp = gb_tmp.get_group(dowy)['swe_m']\n",
    "    error_tmp.index = error_tmp.index.year\n",
    "    swe_tmp.index = swe_tmp.index.year\n",
    "    \n",
    "    error_df.loc[site['station_name']] = error_tmp\n",
    "    swe_df.loc[site['station_name']] = swe_tmp\n",
    "    \n",
    "\n",
    "error_df['map_number'] = pd.Series(sites['map_number'].values, index=sites['station_name'])\n",
    "swe_df['map_number'] = pd.Series(sites['map_number'].values, index=sites['station_name'])\n",
    "\n",
    "error_df.to_csv('data/apr1_cumulative_nonion_error_by_year.csv')\n",
    "swe_df.to_csv('data/apr1_swe_by_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3 - boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_df = pd.read_csv('data/apr1_cumulative_nonion_error_by_year.csv', index_col=0)\n",
    "swe_df = pd.read_csv('data/apr1_swe_by_year.csv', index_col=0)\n",
    "error_df = error_df.astype(float)\n",
    "error_cols = [c for c in error_df.columns if 'map' not in c]\n",
    "rel_error_df = error_df[error_cols] / swe_df[error_cols] * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5*2, 6.5*2))\n",
    "error_df.sort_values('map_number', ascending=False).drop(columns='map_number').T.boxplot(ax=ax, showfliers=False, grid=False, vert=False)\n",
    "\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "ax.set_xlabel('Apr 1 cumulative\\nnon-ion SWE error [m]', fontsize=14, labelpad=12)\n",
    "ax.vlines((0), *ax.get_ylim(), ls='--', color='k', alpha=0.8, lw=1, zorder=0)\n",
    "ax.tick_params(axis='x', labelsize=12, rotation=0)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "ax.set_xlim([-0.21, 0.21])\n",
    "ax.set_xticks(np.arange(-0.15, 0.16, 0.1), minor=True)\n",
    "ax.set_yticklabels(l.get_text().replace(' ','\\n',1) for l in ax.get_yticklabels())                      \n",
    "plt.tight_layout()\n",
    "# fig.savefig('local/figs/initial_submission/figure3.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4 - map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = gpd.read_file('data/median_cumulative_errors_april1.csv')\n",
    "sites['ecoregion'].replace('', np.nan, inplace=True)\n",
    "sites.dropna(subset='ecoregion', inplace=True)\n",
    "sites['map_number'] = [1,3,7,8,4,9,10,2,5,6,11,12,13]\n",
    "for c in sites.columns:\n",
    "    try:\n",
    "        sites[c] = pd.to_numeric(sites[c])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "sites['total_error_non_ion'] = sites[['wet_atmo_error_cumsum_rolling','dry_atmo_error_cumsum_rolling',\n",
    "                                      'soil_error_cumsum_rolling','veg_error_cumsum_rolling',\n",
    "                                      'defo_error_cumsum_rolling']].sum(axis=1)\n",
    "sites['total_error'] = sites[['wet_atmo_error_cumsum_rolling','dry_atmo_error_cumsum_rolling',\n",
    "                              'soil_error_cumsum_rolling','veg_error_cumsum_rolling',\n",
    "                              'defo_error_cumsum_rolling','ion_error_cumsum_rolling']].sum(axis=1)\n",
    "\n",
    "        \n",
    "sites['geometry'] = gpd.points_from_xy(sites['lon'], sites['lat'], crs='epsg:4326')\n",
    "sites = gpd.GeoDataFrame(sites).to_crs('epsg:3857')\n",
    "sites = sites.loc[sites['ecoregion']!='']\n",
    "\n",
    "countries = cfeature.NaturalEarthFeature(\n",
    "        category='cultural',\n",
    "        name='admin_0_boundary_lines_land',\n",
    "        scale='10m',\n",
    "        facecolor='none')\n",
    "\n",
    "states_provinces = cfeature.NaturalEarthFeature(\n",
    "        category='cultural',\n",
    "        name='admin_1_states_provinces_lines',\n",
    "        scale='10m',\n",
    "        facecolor='none')\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(projection=ccrs.epsg(3857))\n",
    "ax.coastlines()\n",
    "# ax.\n",
    "ax.add_feature(countries)\n",
    "ax.add_feature(states_provinces)\n",
    "minx, miny, maxx, maxy = sites.total_bounds\n",
    "minx *= 1.03\n",
    "maxx *= 0.96\n",
    "miny *= 0.9\n",
    "maxy *= 1.05\n",
    "ax.set_extent((minx, maxx, miny, maxy), crs=ccrs.epsg(3857))\n",
    "\n",
    "color_dict = {1:'#8d00bb',2:'#0e8bff',3:'#fb0006',4:'#dfd826',5:'#e96c20',6:'#1bda02',7:'#9a9a9a'}\n",
    "# cbar.ax.xaxis.set_ticks(np.arange(1.5,7,1), labels=['Tundra','Boreal\\nForest','Maritime','Ephemeral','Prairie','Montane\\nForest'])\n",
    "sturm_colors_sites = [color_dict[x] for x in sites['sturm']]\n",
    "sites['sturm_colors'] = sturm_colors_sites\n",
    "\n",
    "sturm_colors = list(color_dict.values())[:-1]\n",
    "sturm_cmap = mcolors.ListedColormap(sturm_colors)\n",
    "bounds = np.arange(1,8)\n",
    "sturm_norm = mcolors.BoundaryNorm(bounds, sturm_cmap.N)\n",
    "\n",
    "sites['geometry'].plot(ax=ax, color=sites['sturm_colors'], markersize=100, edgecolor='k', linewidth=2, zorder=100)\n",
    "ax.scatter((),(), marker='o', s=100, color=color_dict[3], edgecolor='k', linewidth=1.5, label='Maritime')\n",
    "ax.scatter((),(), marker='o', s=100, color=color_dict[6], edgecolor='k', linewidth=1.5, label='Montane\\nForest')\n",
    "ax.scatter((),(), marker='o', s=100, color=color_dict[4], edgecolor='k', linewidth=1.5, label='Ephemeral')\n",
    "ax.scatter((),(), marker='o', s=100, color=color_dict[2], edgecolor='k', linewidth=1.5, label='Boreal\\nForest')\n",
    "ax.scatter((),(), marker='o', s=100, color=color_dict[5], edgecolor='k', linewidth=1.5, label='Prairie')\n",
    "# Add legend below\n",
    "\n",
    "\n",
    "\n",
    "sites['ax_x'] = (sites['geometry'].x - minx) / (maxx-minx)\n",
    "sites['ax_y'] = (sites['geometry'].y - miny) / (maxy-miny)\n",
    "# colors = [plt.get_cmap('tab10')(i) for i in range(8)]\n",
    "colors = {'defo_error_cumsum':plt.get_cmap('tab10')(3), 'soil_error_cumsum':plt.get_cmap('tab10')(5),\n",
    "          'veg_error_cumsum':plt.get_cmap('tab10')(2), 'dry_atmo_error_cumsum':plt.get_cmap('tab10')(1),\n",
    "          'wet_atmo_error_cumsum':plt.get_cmap('tab10')(0), 'cumsum_no_ion':'k'}\n",
    "colors = ['k', plt.get_cmap('tab10')(0), plt.get_cmap('tab10')(1), plt.get_cmap('tab10')(5), plt.get_cmap('tab10')(2), plt.get_cmap('tab10')(3)]\n",
    "widths = [0.8, 0.8, 0.8, 0.8, 0.8, 0.8]\n",
    "\n",
    "\n",
    "hline_dict = {0.15:[-0.1,0.1],0.2:[-0.1,0.1],0.3:[-0.15,0.15],0.5:[-0.25,0.25],1.0:[-0.5,0.5],2.0:[-1,1],3.0:[-1.5,1.5],5.0:[-2.5,2.5],10:[-5,-5],20:[-10,10],50:[-25,25]}\n",
    "\n",
    "plot_ionosphere = False\n",
    "\n",
    "\n",
    "if plot_ionosphere:\n",
    "    n_errors = 8\n",
    "    error_order = ['total_error','total_error_non_ion','ion_error_cumsum_rolling','wet_atmo_error_cumsum_rolling',\n",
    "               'dry_atmo_error_cumsum_rolling','soil_error_cumsum_rolling','veg_error_cumsum_rolling',\n",
    "               'defo_error_cumsum_rolling']\n",
    "    error_labels = ['Total error','Total non-ion error','Ionosphere','Wet troposphere','Dry troposphere','Soil perm','Veg perm','Deformation']\n",
    "else:\n",
    "    n_errors = 6\n",
    "    error_order = ['total_error_non_ion','wet_atmo_error_cumsum_rolling','dry_atmo_error_cumsum_rolling',\n",
    "                   'soil_error_cumsum_rolling','veg_error_cumsum_rolling','defo_error_cumsum_rolling']\n",
    "    error_labels = ['Total non-ion error','Wet troposphere','Dry troposphere','Soil permittivity','Veg permittivity','Deformation']\n",
    "    \n",
    "bar_locations = np.arange(n_errors)\n",
    "    \n",
    "ylim = 0.1\n",
    "\n",
    "for i, site in sites.iterrows():\n",
    "    # Create larger patches behind axes\n",
    "    avg_errors = site[error_order] / site['swe_m']\n",
    "#     ax_mini_patch = ax.inset_axes([site['ax_x']+0.01, site['ax_y']+0.01, 0.115, 0.09], transform=ax.transAxes)\n",
    "#     ax_mini_patch.spines[['top','right','left','bottom']].set_visible(False)\n",
    "#     ax_mini_patch.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "#     ax_mini_patch.patch.set_alpha(1.0)\n",
    "    # Create actual axes\n",
    "#     ax_mini = ax.inset_axes([site['ax_x']+0.01, site['ax_y']+0.01, 0.075, 0.09], transform=ax.transAxes)\n",
    "    ax_mini = ax.inset_axes([site['ax_x']+0.01, site['ax_y']+0.01, 0.09, 0.09], transform=ax.transAxes)\n",
    "    ax_mini.patch.set_alpha(1.0)\n",
    "    ax_mini.spines[['top','right','left']].set_visible(True)\n",
    "\n",
    "    triangles = []\n",
    "    for err_type, err in avg_errors.items():\n",
    "        if err > ylim:\n",
    "            triangles.append('^')\n",
    "            avg_errors.loc[err_type] = ylim*0.8\n",
    "        elif err < -ylim:\n",
    "            triangles.append('v')\n",
    "            avg_errors.loc[err_type] = -ylim*0.8\n",
    "        else:\n",
    "            triangles.append('')\n",
    "            \n",
    "    \n",
    "    ax_mini.bar(bar_locations, avg_errors, color=colors, width=widths)\n",
    "    for i, tri in enumerate(triangles):\n",
    "        if tri:\n",
    "            multiplier = -1 if tri == 'v' else 1\n",
    "            ax_mini.plot(i, ylim*multiplier*0.9, tri, color=colors[i], ms=5.8)\n",
    "    # Calculate positions for hlines \n",
    "    max_limit = avg_errors.abs().max()\n",
    "#     print(max_limit)\n",
    "    hlines = [-0.05, 0.05]\n",
    "    ylim = 0.1\n",
    "    for k, v in hline_dict.items():\n",
    "        if max_limit > ylim and max_limit <= k:\n",
    "            hlines = v\n",
    "            ylim = k\n",
    "    hlines = [-0.05,0.05]\n",
    "    ylim = 0.1\n",
    "    ax_mini.hlines(0.0, -0.8, n_errors-0.2, lw=1.5, color='k', ls='-', alpha=0.9)\n",
    "    ax_mini.hlines(hlines, -0.8, n_errors-0.2, lw=1.5, color='k', ls=':', alpha=0.7)\n",
    "    ax_mini.set_yticks(hlines)\n",
    "    ax_mini.yaxis.set_major_formatter(mtick.PercentFormatter(1.0, decimals=0))\n",
    "#     ax_mini.tick_params(axis='both', labelbottom=False, labelleft=False, bottom=False, left=False, labelright=True, pad=-2.5, labelsize=7)\n",
    "    ax_mini.tick_params(axis='both', labelbottom=False, labelleft=False, bottom=False, left=False, labelright=False)\n",
    "    for l in ax_mini.get_yticklabels():\n",
    "        l.set_stretch('ultra-condensed')\n",
    "#         l.set_color('k')\n",
    "#         l.set_weight('bold')\n",
    "    ax_mini.text(site['ax_x']-0.015, site['ax_y'], site['map_number'], color='white', fontsize=14, weight='bold', ha='right', va='center', transform=ax.transAxes,  path_effects=[pe.withStroke(linewidth=4, foreground='black')])\n",
    "\n",
    "    ax_mini.set_ylim([-ylim, ylim])\n",
    "    ax_mini.set_xlim(-1, n_errors)\n",
    "                            \n",
    "# ax_legend = ax.inset_axes([0.66, 0.75, 0.3, 0.2], transform=ax.transAxes) # Upper right\n",
    "# ax_legend = ax.inset_axes([0.355, 0.025, 0.3, 0.23], transform=ax.transAxes) # bottom center\n",
    "ax_legend = ax.inset_axes([0.18, 0.025, 0.28, 0.25], transform=ax.transAxes) # [0.1, 0.025, 0.3, 0.25]\n",
    "ax_legend.patch.set_alpha(1.0)\n",
    "# ax_legend.patch.set_alpha(0.0)\n",
    "ax_legend.spines[['top','right','left','bottom']].set_visible(True)\n",
    "# ax_legend.bar(np.arange(7), np.tile(1,7), color=colors_non_ion)\n",
    "ax_legend.bar(np.arange(n_errors), np.tile(1,n_errors), color=colors[:n_errors])\n",
    "# ax_legend.text(0.5, 1, 'Legend', ha='center', transform=ax_legend.transAxes)\n",
    "ax_legend.text(0.5, 0.05, 'Cumulative error types', fontsize=12, ha='center', transform=ax_legend.transAxes)\n",
    "ax_legend.set_ylim(-0.25, 1.1)\n",
    "ax_legend.tick_params(axis='both', labelbottom=False, labelleft=False, bottom=False, left=False)\n",
    "\n",
    "for i, text in enumerate(error_labels):\n",
    "    if 'Total' in text:\n",
    "        c = 'w'\n",
    "    else:\n",
    "        c = 'k'\n",
    "    ax_legend.text(i-0.18, 0.1, text, rotation=90, c=c)\n",
    "    \n",
    "# Add legend for dashed lines\n",
    "ax_key = ax.inset_axes([0.48, 0.025, 0.23, 0.25], transform=ax.transAxes) # [0.425, 0.025, 0.23, 0.25]\n",
    "ax_key.patch.set_alpha(1.0)\n",
    "ax_key.tick_params(axis='both', labelbottom=False, labelleft=False, bottom=False, left=False)\n",
    "ax_key.set_ylim([-ylim, ylim])\n",
    "ax_key.set_xlim(-1, n_errors)\n",
    "# ax_key.hlines(0.0, -0.8, n_errors-2-0.2, lw=1.5, color='k', ls='-', alpha=0.9)\n",
    "# ax_key.hlines(hlines, -0.8, n_errors-2-0.2, lw=1.5, color='k', ls=':', alpha=0.7)\n",
    "ax_key.hlines(0.0, 1.8, n_errors-0.2, lw=1.5, color='k', ls='-', alpha=0.9)\n",
    "ax_key.hlines(hlines, 1.8, n_errors-0.2, lw=1.5, color='k', ls=':', alpha=0.7)\n",
    "ax_key.text(0.4, 0, '  0%', va='center')\n",
    "ax_key.text(0.4, 0.05, '$+$5%', va='center')\n",
    "ax_key.text(0.4, 0.0905, '$+$10%', va='center')\n",
    "ax_key.text(0.4, -0.05, '$-$5%', va='center')\n",
    "ax_key.text(0.4, -0.092, '$-$10%', va='center')\n",
    "ax_key.text(3.8, 0.02, 'Inset axis key', fontsize=9, ha='center', bbox=dict(linewidth=1, edgecolor='k', facecolor='#bababa'))\n",
    "# ax_key.text(-0.5, 0.175, 'Errors relative to\\nstation SWE', bbox=dict(linewidth=1, edgecolor='k', facecolor='#bababa'))\n",
    "ax_key.text(-0.2, 0, 'Errors relative to\\nApril 1 SWE', fontsize=9, ha='center', va='center', rotation=90)#, bbox=dict(linewidth=1, edgecolor='k', facecolor='#bababa'))\n",
    "        \n",
    "swann_avg = xr.open_dataarray('/pl/active/palomaki-sar/insar_swe_errors/data/ancillary/swann_swe/swann_april1_avg.nc', decode_coords='all')\n",
    "\n",
    "    \n",
    "# sturm = rxr.open_rasterio('/pl/active/palomaki-sar/insar_swe_errors/data/ancillary/SnowClass_NA_300m_10.0arcsec_2021_v01.0.tif').rio.reproject('epsg:3857').rio.clip_box(minx, miny, maxx, maxy)\n",
    "# sturm = sturm.where(sturm<8)\n",
    "# mesh = sturm.plot(ax=ax, zorder=0, cmap=sturm_cmap, norm=sturm_norm, add_colorbar=False)\n",
    "mesh = (swann_avg/1000).plot(ax=ax, zorder=0, cmap='Blues', add_colorbar=False, vmin=0, vmax=2)\n",
    "cbar = plt.colorbar(mesh, extend='max', orientation='horizontal', shrink=0.895, pad=0.02)\n",
    "# cbar.ax.xaxis.set_ticks(np.arange(1.5,7,1), labels=['Tundra','Boreal\\nForest','Maritime','Ephemeral','Prairie','Montane\\nForest'])\n",
    "# cbar.ax.set_xlabel('Sturm and Liston (2021) snow class (background map)', labelpad=18, fontsize=16)\n",
    "cbar.ax.set_xlabel('Average April 1 SWE [m]', labelpad=18, fontsize=14)\n",
    "cbar.ax.tick_params(axis='x', which='major', labelsize=12)\n",
    "cbar.ax.tick_params(axis='x', which='minor', bottom=False)\n",
    "ax.set_title('')\n",
    "\n",
    "pos = ax_legend.get_position()\n",
    "\n",
    "ax_snowclass = ax.inset_axes([0.01, 0.025, 0.15, 0.25], transform=ax.transAxes)\n",
    "ax_snowclass.patch.set_alpha(1.0)\n",
    "ax_snowclass.spines[['top','right','left','bottom']].set_visible(True)\n",
    "ax_snowclass.tick_params(axis='both', bottom=False, left=False,\n",
    "                         labelbottom=False, labelleft=False)\n",
    "\n",
    "# Add a title like ax.legend(title=...)\n",
    "# ax_snowclass.set_title('Snow Class', fontsize='large')\n",
    "\n",
    "# Define labels and colors in the order you want them\n",
    "legend_items = [\n",
    "    ('Maritime',        color_dict[3]),\n",
    "    ('Montane\\nForest', color_dict[6]),\n",
    "    ('Ephemeral',       color_dict[4]),\n",
    "    ('Boreal\\nForest',  color_dict[2]),\n",
    "    ('Prairie',         color_dict[5])\n",
    "]\n",
    "\n",
    "# Draw scatter markers and text manually\n",
    "for i, (label, color) in enumerate(legend_items):\n",
    "    y = 0.92 - (i+1)*0.17  # vertical spacing between entries\n",
    "    ax_snowclass.scatter(0.13, y, marker='o', s=100, color=color,\n",
    "                         edgecolor='k', linewidth=1.5, transform=ax_snowclass.transAxes)\n",
    "    ax_snowclass.text(0.25, y, label, transform=ax_snowclass.transAxes,\n",
    "                      va='center', ha='left', fontsize=10)\n",
    "\n",
    "# Lock the viewbox\n",
    "ax_snowclass.text(0.5, 0.9, 'Snow class', ha='center', va='center', fontsize=12, transform=ax_snowclass.transAxes)\n",
    "ax_snowclass.set_xlim(0, 1)\n",
    "ax_snowclass.set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig('local/figs/initial_submission/figure4.png', dpi=1200)\n",
    "# fig.savefig('local/figs/figure4.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5 - seasonal errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_title_dict = {'Paradise':' (Deep snowpack)','Trial Lake':' (Moderate snowpack)','Disaster Peak':' (Shallow snowpack)'}\n",
    "\n",
    "fig, ax = plt.subplots(6, 3, figsize=(15*0.8,24*0.6))\n",
    "plot_temporal_variability(station_id=679, ax=ax[:,0], extra_title_dict=extra_title_dict, return_data=False)\n",
    "plot_temporal_variability(station_id=828, ax=ax[:,1], extra_title_dict=extra_title_dict, return_data=False)\n",
    "plot_temporal_variability(station_id=445, ax=ax[:,2], extra_title_dict=extra_title_dict, return_data=False)\n",
    "\n",
    "for axx in ax[0]:\n",
    "    axx.set_ylim(-0.011, 0.011)\n",
    "    \n",
    "for axx in ax[1]:\n",
    "    axx.set_ylim(-0.023, 0.023)\n",
    "    \n",
    "for axx in ax[2]:\n",
    "    axx.set_ylim(-0.023, 0.023)\n",
    "    \n",
    "for axx in ax[3]:\n",
    "    axx.set_ylim(-0.044, 0.044)\n",
    "    \n",
    "for axx in ax[4]:\n",
    "    axx.set_ylim(-0.063, 0.063)\n",
    "    \n",
    "for axx in ax[5]:\n",
    "    axx.set_ylim(-2.3, 2.3)\n",
    "    \n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    for axx in ax[i]:\n",
    "        axx.hlines(0, 1, 274, lw=1.5, color='k', ls='--', zorder=0)\n",
    "        axx.set_xlim(1,274)\n",
    "\n",
    "\n",
    "for axx in ax[:,0]:\n",
    "    axx.set_ylabel('SWE error [m]', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig('local/figs/initial_submission/figure5.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6 - exceedance curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/big_timeseries.csv', index_col=[0,1], parse_dates=True)\n",
    "dowy_thresh = 183 # apr1 = 183\n",
    "df = df.loc[df['dowy'] <= dowy_thresh]\n",
    "\n",
    "cdfs = pd.DataFrame(index=np.arange(len(df.index)))\n",
    "error_cols = ['total_error','non_ion_error','ion_error','wet_atmo_error','dry_atmo_error','soil_error','veg_error','defo_error']\n",
    "labels = ['Total error','Total non-ion','Ionosphere','Wet tropo','Dry tropo','Soil perm','Veg perm','Deformation']\n",
    "colors = ['r','k'] + [plt.get_cmap('tab10')(i) for i in range(6)]\n",
    "\n",
    "color_dict = {'total_error':'r','non_ion_error':'k','defo_error':plt.get_cmap('tab10')(3), 'soil_error':plt.get_cmap('tab10')(5),\n",
    "          'veg_error':plt.get_cmap('tab10')(2), 'dry_atmo_error':plt.get_cmap('tab10')(1),\n",
    "          'wet_atmo_error':plt.get_cmap('tab10')(0), 'ion_error':plt.get_cmap('tab10')(4)}\n",
    "\n",
    "for err in error_cols:\n",
    "    abs_err_sorted = df[err].abs().dropna().sort_values().reset_index(drop=True)\n",
    "    cdf = (1 - abs_err_sorted.rank(method='first') / len(abs_err_sorted)) * 100\n",
    "    cdfs[f'{err}_sorted'] = abs_err_sorted\n",
    "    cdfs[f'{err}_cdf'] = cdf.reset_index(drop=True)\n",
    "    \n",
    "# CDFs relative to dSWE\n",
    "dswe_thresh = 0.01\n",
    "df_accum = df.loc[df['swe_change'] >= dswe_thresh]\n",
    "cdfs_accum = pd.DataFrame(index=np.arange(len(df_accum.index)))\n",
    "for err in error_cols:\n",
    "    err_valid = df_accum[err].dropna()\n",
    "    err_tmp = err_valid / df_accum.loc[err_valid.index, 'swe_change']\n",
    "    abs_err_sorted = err_tmp.abs().sort_values().reset_index(drop=True)\n",
    "    cdf = (1 - abs_err_sorted.rank(method='first') / len(abs_err_sorted)) * 100\n",
    "    cdfs_accum[f'{err}_sorted'] = abs_err_sorted\n",
    "    cdfs_accum[f'{err}_cdf'] = cdf\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "for i, err in enumerate(error_cols):\n",
    "    if err == 'total_error' or err == 'non_ion_error':\n",
    "        lw = 3.5\n",
    "        zorder=10\n",
    "    else:\n",
    "        lw = 1.5\n",
    "        zorder=1\n",
    "    ax[0].plot(cdfs[f'{err}_sorted'], cdfs[f'{err}_cdf'], lw=lw, color=color_dict[err], label=labels[i], zorder=zorder)\n",
    "#     ax[1].plot(cdfs_accum[f'{err}_sorted'], cdfs_accum[f'{err}_cdf'], lw=lw, color=color_dict[err], label=labels[i], zorder=zorder)\n",
    "    \n",
    "idx_cdfs = (cdfs['total_error_cdf'] - 50).abs().idxmin()\n",
    "idx_cdfs_accum = (cdfs_accum['total_error_cdf'] - 50).abs().idxmin()\n",
    "\n",
    "ax[0].scatter((cdfs.loc[idx_cdfs, ['total_error_sorted','non_ion_error_sorted']]), (50,50), marker='o', c='none', linewidths=2.0, edgecolors='0.4', s=80, zorder=100)\n",
    "    \n",
    "ax[0].legend(ncols=2)\n",
    "ax[0].set_xlabel('12-day error magnitude [m]', fontsize=14, labelpad=12)\n",
    "ax[0].set_ylabel('Exceedance probability [%]', fontsize=14, labelpad=6)\n",
    "ax[0].set_xlim([-0.01, 0.31])\n",
    "ax[0].set_ylim([-2, 102])\n",
    "ax[0].set_yticks([0,20,40,50,60,80,100])\n",
    "# ax[0].set_xticks(np.arange(0.05, 0.31, 0.1), minor=True)\n",
    "ax[0].tick_params(axis='both', labelsize=12)\n",
    "ax[0].grid(False, which='both')\n",
    "ax[0].set_title('All stations, WYs 2016$-$25, October 1$-$April 1 (n = 23,397)')\n",
    "ax[0].hlines(50, *ax[0].get_xlim(), ls=':', color='k', lw=2, alpha=0.8, zorder=0)\n",
    "ax[0].vlines(cdfs.loc[idx_cdfs, ['total_error_sorted','non_ion_error_sorted']], ax[0].get_ylim()[0], 50, ls=':', color='k', lw=2, alpha=0.8, zorder=0)\n",
    "\n",
    "# CDFs relative to dSWE\n",
    "df_dict = {}\n",
    "labels = []\n",
    "\n",
    "for thresh in [0.01, 0.02, 0.05, 0.1, 0.2]:\n",
    "    dswe_thresh = thresh\n",
    "    df_accum = df.loc[df['swe_change'] >= dswe_thresh]\n",
    "    cdfs_accum = pd.DataFrame(index=np.arange(len(df_accum.index)))\n",
    "    for err in error_cols:\n",
    "        err_valid = df_accum[err].dropna()\n",
    "        err_tmp = err_valid / df_accum.loc[err_valid.index, 'swe_change']\n",
    "        abs_err_sorted = err_tmp.abs().sort_values().reset_index(drop=True)\n",
    "        cdf = (1 - abs_err_sorted.rank(method='first') / len(abs_err_sorted)) * 100\n",
    "        cdfs_accum[f'{err}_sorted'] = abs_err_sorted\n",
    "        cdfs_accum[f'{err}_cdf'] = cdf\n",
    "    thresh_str = f'{float(thresh): .2f}'\n",
    "    df_dict[f'thresh_{thresh_str}'] = cdfs_accum\n",
    "    labels.append(f'$\\Delta$SWE ≥{thresh_str}m (n = {cdfs_accum[\"non_ion_error_sorted\"].notnull().sum()})')\n",
    "\n",
    "    \n",
    "cmap = plt.get_cmap('Blues')\n",
    "colors = cmap(np.linspace(0,1,7))\n",
    "\n",
    "for i, (thresh_str, df) in enumerate(df_dict.items()):\n",
    "    ax[1].plot(df[f'non_ion_error_sorted'], df[f'non_ion_error_cdf'], lw=2, color=colors[i+2], label=labels[i])    \n",
    "    idx_cdfs_accum = (df['total_error_cdf'] - 50).abs().idxmin()\n",
    "    ax[1].scatter((df.loc[idx_cdfs_accum, 'non_ion_error_sorted']), 50, marker='o', c='none', linewidths=2.0, edgecolors='0.4', s=80, zorder=100)\n",
    "    ax[1].vlines(df.loc[idx_cdfs_accum, 'non_ion_error_sorted'], ax[1].get_ylim()[0], 50, ls=':', color='k', lw=2, alpha=0.6, zorder=0)\n",
    "\n",
    "ax[1].legend(ncols=1, loc='upper right')\n",
    "ax[1].set_xlabel('12-day error magnitude [% relative to $\\Delta$SWE]', fontsize=14, labelpad=12)\n",
    "ax[1].set_ylabel('Exceedance probability [%]', fontsize=14, labelpad=6)\n",
    "ax[1].set_xlim([-0.02, 1.02])\n",
    "ax[1].set_ylim([-2, 102])\n",
    "ax[1].set_yticks([0,20,40,50,60,80,100])\n",
    "# ax[1].set_xticks(np.arange(0.5, 4.51, 1), minor=True)\n",
    "ax[1].tick_params(axis='both', labelsize=12)\n",
    "ax[1].grid(False, which='both')\n",
    "ax[1].set_title('Relative total non-ion error for $\\Delta$SWE ≥ threshold')\n",
    "ax[1].hlines(50, *ax[1].get_xlim(), ls=':', color='k', lw=2, alpha=0.8, zorder=0)\n",
    "\n",
    "ax[1].xaxis.set_major_formatter(mtick.PercentFormatter(1.0, decimals=0))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig('local/figs/initial_submission/figure6.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 7 - transects\n",
    "\n",
    "See code in `src/analysis/play/transect_figure.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "gis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
